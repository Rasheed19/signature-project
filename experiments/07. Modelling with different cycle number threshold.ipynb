{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from utils import utils_gn, utils_dgrd, utils_models\n",
    "import importlib\n",
    "importlib.reload(utils_gn)\n",
    "importlib.reload(utils_models)\n",
    "importlib.reload(utils_dgrd)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the impact of Cycle number threshold on Model accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we fix the number of signature levels and vary the input cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train raw data\n",
    "train_raw = utils_gn.read_data('train_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_raw = utils_gn.read_data('test_1238.pkl')\n",
    "y_test_raw = utils_gn.read_data('true_test_labels_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cycles = np.arange(10, 101, 2)\n",
    "list_of_cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosing_best_n_cross_val(target_list, model_type, n_list, fixed_level, ylabels):\n",
    "\n",
    "        '''\n",
    "        Function that investigates the effect of cycle number threshold on modelling through cross-validation.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "                target_list: list of targets to predict\n",
    "                model_type:  \"cycle\" (predict cycles) or \"capacity-ir\" (predict values at cycles)\n",
    "                n_list:      a list of cycle number thresholds\n",
    "                fixed_level: a fixed number of signature level\n",
    "                ylabels:     a list of labels for y-axis\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "                dictionary of error metrics.            \n",
    "        '''\n",
    "        \n",
    "        # Split targets based on capacity/IR\n",
    "        if model_type == \"cycle\":\n",
    "                split_list = [target_list[:3], target_list[3:]]\n",
    "        elif model_type == \"capacity-ir\":\n",
    "                split_list = [target_list[:2], target_list[2:]]\n",
    "\n",
    "        _, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "        dict_of_res = {}\n",
    "\n",
    "        for i, split in enumerate(split_list):\n",
    "\n",
    "            this_mae, this_rmse = [], []\n",
    "            mae_ci, rmse_ci = [], []\n",
    "        \n",
    "            for n in n_list:\n",
    "                print('n: ', n)\n",
    "                \n",
    "                # Get training set\n",
    "                tr = utils_gn.FeatureTransformation(n=n)\n",
    "                X_train, y_train = tr.fit_transform(data=train_raw, targets=target_list, with_eol=True, sig_level=fixed_level)\n",
    "\n",
    "\n",
    "                # Build model\n",
    "                if model_type == \"cycle\":\n",
    "\n",
    "                        # Choose the best hyperparameters based on eol\n",
    "                        model_gs = TransformedTargetRegressor(XGBRegressor(), func=np.log10, inverse_func=utils_models.antilog)\n",
    "                        params = {'regressor__model__n_estimators': [50, 60, 100],\n",
    "                                'regressor__model__learning_rate': [0.1, 0.2],\n",
    "                                'regressor__model__max_depth':[2, 3, 4, 5]\n",
    "                                }\n",
    "                        gs = GridSearchCV(estimator=model_gs, param_grid=params, scoring='neg_mean_absolute_error', cv=3).fit(X_train, y_train[:, -1])\n",
    "\n",
    "                        model = TransformedTargetRegressor(MultiOutputRegressor(XGBRegressor(n_estimators=gs.best_params_['regressor__model__n_estimators'],\n",
    "                                                                                                max_depth=gs.best_params_['regressor__model__max_depth'],\n",
    "                                                                                                learning_rate=gs.best_params_['regressor__model__learning_rate'])),\n",
    "                                                                                func=np.log10,\n",
    "                                                                                inverse_func=utils_models.antilog)\n",
    "                elif model_type == \"capacity-ir\":\n",
    "                        \n",
    "                        # Choose the best hyperparameters based on ir at eol\n",
    "                        model_gs = TransformedTargetRegressor(XGBRegressor(), func=np.log10, inverse_func=utils_models.antilog)\n",
    "                        params = {'regressor__model__n_estimators': [300, 400, 500],\n",
    "                                'regressor__model__learning_rate': [0.1, 0.2],\n",
    "                                'regressor__model__max_depth':[3, 4, 5, 6]\n",
    "                                }\n",
    "                        gs = GridSearchCV(estimator=model_gs, param_grid=params, scoring='neg_mean_absolute_error', cv=3).fit(X_train, y_train[:, -1])\n",
    "\n",
    "                        model = TransformedTargetRegressor(MultiOutputRegressor(XGBRegressor(n_estimators=gs.best_params_['regressor__model__n_estimators'],\n",
    "                                                                                                max_depth=gs.best_params_['regressor__model__max_depth'],\n",
    "                                                                                                learning_rate=gs.best_params_['regressor__model__learning_rate'])),\n",
    "                                                                                func=np.log10,\n",
    "                                                                                inverse_func=utils_models.antilog)\n",
    "                # Call repeated k-fold cross-validation on the training set\n",
    "                val_scores, val_scores_raw = utils_models.kfold_cross_validation(X=X_train, y=y_train, model=model, cv=5)\n",
    "                \n",
    "                # Append the scores to the list of metrics\n",
    "                this_mae.append(val_scores['test_MAE'])\n",
    "                this_rmse.append(val_scores['test_RMSE'])\n",
    "\n",
    "                # Calculate the CI\n",
    "                mae_ci.append(utils_models.confidence_interval_any(values=val_scores_raw['test_MAE'], n_bootstraps=1000, alpha=0.1))\n",
    "                rmse_ci.append(utils_models.confidence_interval_any(values=val_scores_raw['test_RMSE'], n_bootstraps=1000, alpha=0.1))\n",
    "\n",
    "            # Cast to numpy array\n",
    "            mae_ci = np.array(mae_ci)\n",
    "            rmse_ci = np.array(rmse_ci)\n",
    "            \n",
    "            # Store the current results in a dictionary\n",
    "            dict_of_res['data_'+str(i)] = this_mae, mae_ci, this_rmse, rmse_ci\n",
    "\n",
    "            ax[i].plot(n_list, this_mae, 'D--', label='MAE', color='blue', markersize=5)\n",
    "            ax[i].fill_between(n_list, mae_ci[:, 0], mae_ci[:, 1], color='blue', alpha=0.1, label='MAE: 90% CI')\n",
    "\n",
    "            ax[i].set_xlabel('Input cycle number', fontsize=16)\n",
    "           \n",
    "            ax[i].set_ylabel(ylabels[i], fontsize=16)\n",
    "            ax[i].set_title(', '.join(split), fontsize=18)\n",
    "\n",
    "            ax[i].plot(n_list, this_rmse, 's-', color='crimson', label='RMSE', markersize=5)\n",
    "            ax[i].fill_between(n_list, rmse_ci[:, 0], rmse_ci[:, 1], color='crimson', alpha=0.1, label='RMSE: 90% CI')\n",
    "    \n",
    "        \n",
    "        handles, labels = ax[0].get_legend_handles_labels()\n",
    "        ax[0].legend(handles, labels, loc='upper center', ncol=4, fontsize=16, bbox_to_anchor=(1.0, -0.15))\n",
    "\n",
    "\n",
    "        if model_type == \"cycle\":\n",
    "               plt.savefig(fname=\"plots/sig_level2_crossval_n_effect_cycle_tabs12.pdf\", bbox_inches='tight')\n",
    "        else:\n",
    "               plt.savefig(fname=\"plots/sig_level2_crossval_n_effect_capir_tabs12.pdf\", bbox_inches='tight')\n",
    "        \n",
    "        return dict_of_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the model that predicts cycles\n",
    "dict_cycle_model = choosing_best_n_cross_val(target_list=['k-o', 'k-p', 'EOL', 'e-o', 'e-p'], model_type=\"cycle\", n_list=list_of_cycles, fixed_level=2,\n",
    "                          ylabels=['Cross-validated errors (cycles)', 'Cross-validated errors (cycles)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the model that predicts capacities/internal resistance\n",
    "dict_capacity_ir_model = choosing_best_n_cross_val(target_list=['Qatk-o', 'Qatk-p', 'IRate-o', 'IRate-p', 'IRatEOL'],\n",
    "                                                   model_type=\"capacity-ir\",\n",
    "                                                   n_list=list_of_cycles,\n",
    "                                                   fixed_level=2,\n",
    "                                                   ylabels=['Cross-validated errors (Ah)', r'Cross-validated errors ($\\Omega$)']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(\"data\", \"sig_vary_n_cap_ir_model.pkl\"), \"wb\") as fp:\n",
    " #   pickle.dump(dict_capacity_ir_model, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of input cycles on test errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_of_cycle_number_test(target_list, model_type, n_list, ylabels, fixed_level=2):\n",
    "\n",
    "        \"\"\"\n",
    "        Function to plot average test errors for different cycle number threshold.\n",
    "\n",
    "        Args:\n",
    "        ----\n",
    "                target_list: list of target to predict\n",
    "                model_type:  \"cycle\" (predict cycles) or \"capacity-ir\" (predict values at cycles)\n",
    "                n_list:      a list of cycle number thresholds\n",
    "                ylabels:     a list of y labels\n",
    "                fixed_level: fixed level of signature\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "                a plot of test average errors vs cycle numbers.              \n",
    "        \"\"\"\n",
    "        \n",
    "        # Split targets based on capacity/IR\n",
    "        if model_type == \"cycle\":\n",
    "                split_list = [target_list[:3], target_list[3:]]\n",
    "        elif model_type == \"capacity-ir\":\n",
    "                split_list = [target_list[:2], target_list[2:]]\n",
    "\n",
    "        _, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "        for i, split in enumerate(split_list):\n",
    "\n",
    "                this_mae, this_rmse = [], []\n",
    "                mae_ci, rmse_ci = [], []\n",
    "        \n",
    "                for n in n_list:\n",
    "                        print('n: ', n)\n",
    "\n",
    "                        # Get training set\n",
    "                        tr = utils_gn.FeatureTransformation(n=n)\n",
    "                        X_train, y_train = tr.fit_transform(data=train_raw, targets=target_list, with_eol=True, sig_level=fixed_level)\n",
    "                        X_test, y_test = tr.transform(test_raw, sig_level=fixed_level), y_test_raw[target_list].values\n",
    "\n",
    "\n",
    "                        # Build model\n",
    "                        if model_type == \"cycle\":\n",
    "                                params = {'n_estimators': 100, 'reg_alpha': 0.1, 'max_depth': 2, 'min_samples_split': 3}   # model from Jupyter notebook 5\n",
    "                                model = TransformedTargetRegressor(MultiOutputRegressor(XGBRegressor(**params)),\n",
    "                                                                                        func=np.log10,\n",
    "                                                                                        inverse_func=utils_models.antilog)\n",
    "                        elif model_type == \"capacity-ir\":\n",
    "                                params = {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.1}    # model from Jupyter notebook 6\n",
    "                                model = TransformedTargetRegressor(MultiOutputRegressor(XGBRegressor(**params)), \n",
    "                                                                                        func=np.log10,\n",
    "                                                                                        inverse_func=utils_models.antilog)\n",
    "                        model = model.fit(X_train, y_train)\n",
    "                        \n",
    "                        # Get validation scores\n",
    "                        test_scores = utils_models.metrics_calculator(y_test, model.predict(X_test))\n",
    "                        this_mae.append(test_scores['MAE'])\n",
    "                        this_rmse.append(test_scores['RMSE'])\n",
    "\n",
    "                        error = np.ravel((y_test - model.predict(X_test)))\n",
    "\n",
    "                        # Calculate the CI\n",
    "                        mae_ci.append(utils_models.confidence_interval_any(values=abs(error), n_bootstraps=1000, alpha=0.1))\n",
    "                        rmse_ci.append(utils_models.confidence_interval_any(values=error, n_bootstraps=1000, metric_type='rmse', alpha=0.1))\n",
    "\n",
    "                \n",
    "                # Cast to numpy array\n",
    "                mae_ci = np.array(mae_ci)\n",
    "                rmse_ci = np.array(rmse_ci)\n",
    "\n",
    "                ax[i].plot(n_list, this_mae, 'D--', label='MAE', color='blue', markersize=5)\n",
    "                ax[i].fill_between(n_list, mae_ci[:, 0], mae_ci[:, 1], color='blue', alpha=0.1, label='MAE: 90% CI')\n",
    "\n",
    "              \n",
    "                ax[i].set_xlabel('Input cycle number', fontsize=16)\n",
    "                        \n",
    "                ax[i].set_ylabel(ylabels[i], fontsize=16)\n",
    "                ax[i].set_title(', '.join(split), fontsize=18)\n",
    "               \n",
    "\n",
    "                ax[i].plot(n_list, this_rmse, 's-', color='crimson', label='RMSE', markersize=5)\n",
    "                ax[i].fill_between(n_list, rmse_ci[:, 0], rmse_ci[:, 1], color='crimson', alpha=0.1, label='RMSE: 90% CI')\n",
    "           \n",
    "        handles, labels = ax[0].get_legend_handles_labels()\n",
    "        ax[0].legend(handles, labels, loc='upper center', ncol=4, fontsize=16, bbox_to_anchor=(1.0, -0.15))\n",
    "\n",
    "        if model_type == \"cycle\":\n",
    "                plt.savefig(fname=\"plots/sig_level2_test_n_effect_cycles_tabs12.pdf\", bbox_inches='tight')\n",
    "        else:\n",
    "                plt.savefig(fname=\"plots/sig_level2_test_n_effect_capir_tabs12.pdf\", bbox_inches='tight')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_of_cycle_number_test(target_list=['k-o', 'k-p', 'EOL', 'e-o', 'e-p'],\n",
    "                            model_type=\"cycle\",\n",
    "                            n_list=list_of_cycles,\n",
    "                            ylabels=['Average test errors (cycles)', 'Average test errors (cycles)'],\n",
    "                            fixed_level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_of_cycle_number_test(target_list=['Qatk-o', 'Qatk-p', 'IRate-o', 'IRate-p', 'IRatEOL'],\n",
    "                            model_type=\"capacity-ir\",\n",
    "                            n_list=list_of_cycles,\n",
    "                            ylabels=['Average test errors (Ah)', r'Average test errors ($\\Omega$)'],\n",
    "                            fixed_level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
