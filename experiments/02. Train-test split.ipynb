{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils import utils_gn, utils_dgrd\n",
    "import importlib\n",
    "importlib.reload(utils_gn)\n",
    "importlib.reload(utils_dgrd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we remove all cells whose end of life (EOL) is greater than 1200, a data prpcessing step. We also remove cells that belong to batches 4 to 7 as they are cycled pass what can be regarded as EOL. Also, we will split the *raw data* into train and test cells, and dump them as pickle files. Although this might be can considered as too early, it is the best practice to carry out exploration and transformation only on the train data. This will curb *peeping into the test data*, *over-fitting* and *biasedness*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the batches \n",
    "batch = utils_gn.read_data('data_101cycles_ir.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove batteries with more than 1200 cycle life and those belong to batches 4 to 7\n",
    "odd_cells = []\n",
    "\n",
    "for cell in batch.keys():\n",
    "    Qd = batch[cell]['summary']['QDischarge']\n",
    "    Qd_eol = Qd >= .88   # eol is defined as cycle number at 80% of nominal capacity\n",
    "    Qd = Qd[Qd_eol]\n",
    "    if np.any([len(Qd) > 1200, cell[:2] in ('b4', 'b5', 'b6', 'b7')]):\n",
    "        odd_cells.append(cell) \n",
    "odd_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number cells left \n",
    "new_batch = {k: batch[k] for k in batch.keys() if k not in odd_cells}\n",
    "len(new_batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into 70-30% train-test and dump in a pickle file\n",
    "train, test = utils_gn.split_train_test_by_id(new_batch, test_ratio=0.3)\n",
    "\n",
    "with open(os.path.join(\"data\", \"train_1238.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(train, fp)\n",
    "\n",
    "with open(os.path.join(\"data\", \"test_1238.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the true labels for the test data\n",
    "true_test_labels = utils_dgrd.create_knee_elbow_data(test)\n",
    "with open(os.path.join(\"data\", \"true_test_labels_1238.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(true_test_labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the true labels for the train data\n",
    "true_train_labels = utils_dgrd.create_knee_elbow_data(train)\n",
    "with open(os.path.join(\"data\", \"true_train_labels_1238.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(true_train_labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
