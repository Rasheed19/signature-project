{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import scipy.stats as st\n",
    "from utils import utils_gn, utils_dgrd, utils_models\n",
    "import importlib\n",
    "from xgboost import XGBRegressor\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import seaborn as sns\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "importlib.reload(utils_gn)\n",
    "importlib.reload(utils_models)\n",
    "importlib.reload(utils_dgrd)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train raw data\n",
    "train_raw = utils_gn.read_data('train_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_raw = utils_gn.read_data('test_1238.pkl')\n",
    "y_test_raw = utils_gn.read_data('true_test_labels_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sub-sampling time step codes\n",
    "step_size_dict = utils_models.create_time_steps()\n",
    "step_size_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "def ccv_sampling_eol_cross_val():\n",
    "   \n",
    "    error_metrics = []\n",
    "    mae_ci, rmse_ci = [], []\n",
    "\n",
    "    time_map = step_size_dict\n",
    "\n",
    "    # Build model\n",
    "    params = {'n_estimators': 100, 'reg_alpha': 0.1, 'max_depth': 2, 'min_samples_split': 3}\n",
    "    for time in time_map.keys():\n",
    "\n",
    "        tr = utils_gn.FeatureTransformation(n=100, step_size=time)\n",
    "        X_train, y_train = tr.fit_transform(data=train_raw, targets=['EOL'], with_eol=True, sig_level=2)\n",
    "\n",
    "        model = TransformedTargetRegressor(XGBRegressor(**params), func=np.log10, inverse_func=utils_models.antilog)\n",
    "\n",
    "        # Call k-fold cross-validation on the training set\n",
    "        val_scores, val_scores_raw = utils_models.kfold_cross_validation(X=X_train, y=y_train, model=model, cv=3)\n",
    "        error_metrics.append(list(val_scores.values()))\n",
    "\n",
    "        # Calculate the 95% CI\n",
    "        mae_ci.append(utils_models.confidence_interval_any(values=val_scores_raw['test_MAE'], n_bootstraps=10000, alpha=0.1))\n",
    "        rmse_ci.append(utils_models.confidence_interval_any(values=val_scores_raw['test_RMSE'], n_bootstraps=10000, alpha=0.1))\n",
    "        #mae_raw = val_scores_raw['test_MAE']\n",
    "        #rmse_raw = val_scores_raw['test_RMSE']\n",
    "        #mae_ci.append(st.t.interval(alpha=0.9, df=len(mae_raw)-1, loc=np.mean(mae_raw), scale=st.sem(mae_raw)))\n",
    "        #rmse_ci.append(st.t.interval(alpha=0.9, df=len(rmse_raw)-1, loc=np.mean(rmse_raw), scale=st.sem(rmse_raw)))\n",
    "\n",
    "        print(f'step size: {time_map[time]} done')\n",
    "\n",
    "    with open(os.path.join(\"data\", \"signature_ccv_subsample_crossval.pkl\"), \"wb\") as fp:\n",
    "        pickle.dump((list(time_map.values()), np.array(error_metrics), np.array(mae_ci), np.array(rmse_ci)), fp)\n",
    "\n",
    "    return list(time_map.values()), np.array(error_metrics), np.array(mae_ci), np.array(rmse_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, error, mae_ci, rmse_ci = ccv_sampling_eol_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4.5))\n",
    "ax[0].plot(time[::2], error[:, 0][::2], 'D--', label='EOL: MAE', color='blue')\n",
    "ax[0].fill_between(time[::2], mae_ci[:, 0][::2], mae_ci[:, 1][::2], color='blue', alpha=0.15, label='MAE: 90% CI')\n",
    "\n",
    "ax[1].plot(time[::2], error[:, 1][::2], 's-', label='EOL: RMSE', color='crimson')\n",
    "ax[1].fill_between(time[::2], rmse_ci[:, 0][::2], rmse_ci[:, 1][::2], color='crimson', alpha=0.15, label='RMSE: 90% CI')\n",
    "\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "ax[0].set_xlabel(\"Sub-sampling time steps (mins)\", fontsize=16)\n",
    "ax[0].set_ylabel(\"Cross-validation errors (cycles)\", fontsize=16)\n",
    "ax[1].set_xlabel(\"Sub-sampling time steps (mins)\", fontsize=16)\n",
    "\n",
    "plt.savefig(fname=\"plots/sig_level2_subsample_tabs12.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the robustness of the XGBoost model and RRCT feature selection to data sub-sampling\n",
    "total_num_features = 10\n",
    "times_needed = np.arange(0, 90, step=10)\n",
    "times_needed[0] = 1\n",
    "times_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model_feature_selection_robustness() to see how similar are the \n",
    "# features selected by the RRCT under (restricted to 10) different\n",
    "# sub-sampling time steps.\n",
    "robust = utils_models.model_feature_selection_robustness(train_raw=train_raw,\n",
    "                                                        test_raw=test_raw,\n",
    "                                                        y_test_df=y_test_raw,\n",
    "                                                        target_list=['EOL'],\n",
    "                                                        params={'n_estimators': 100, 'reg_alpha': 0.1, 'max_depth': 2, 'min_samples_split': 3}, #{'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.1} #\n",
    "                                                        step_size_dict=step_size_dict,\n",
    "                                                        times_needed=times_needed,\n",
    "                                                        k=total_num_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similarity score heat map\n",
    "all_features = robust['Selected features'].values\n",
    "similarity_scores = [\n",
    "    [\n",
    "        len(np.intersect1d(features, others)) / total_num_features\n",
    "        for others in all_features\n",
    "    ]\n",
    "    for features in all_features\n",
    "]\n",
    "similarity_scores = np.array(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 4.5))\n",
    "axis_labels = np.round(robust.index, 2)\n",
    "ax.set_xticklabels(axis_labels)\n",
    "ax.set_yticklabels(axis_labels)\n",
    "sns.heatmap(similarity_scores,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            xticklabels=axis_labels,\n",
    "            yticklabels=axis_labels,\n",
    "            linewidth=0.5,\n",
    "            linecolor='black',\n",
    "            ax=ax,\n",
    "            cbar_kws={'label': 'Similarity scores'},\n",
    "            annot=True)\n",
    "#ax.figure.axes[0].set_xlabel('Similarity scores', size=14)\n",
    "#ax.xaxis.tick_top()\n",
    "\n",
    "ax.set_xlabel(\"Sub-sampling time steps (mins)\", fontsize=16)\n",
    "ax.set_ylabel(\"Sub-sampling time steps (mins)\", fontsize=16)\n",
    "ax.figure.axes[-1].yaxis.label.set_size(16)\n",
    "plt.yticks(rotation=0)\n",
    "plt.savefig(fname=\"plots/sig-similarity-scores.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking robustness through trainig a model on high frequency data and then\n",
    "# testing it on data generated under low frequency data \n",
    "test_model = utils_gn.read_data('sig_capacity_ir.pkl', folder='models')  #utils_gn.read_data('sig_cycles.pkl', folder='models')\n",
    "test_model_tr =  utils_gn.read_data('sig_capacity_ir_trans.pkl', folder='models') #utils_gn.read_data('sig_cycles_trans.pkl', folder='models')\n",
    "time_step_keys = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "targets = ['Qatk-o', 'Qatk-p', 'IRate-o', 'IRate-p', 'IRatEOL']  #['Qatk-o', 'Qatk-p', 'IRate-o', 'IRate-p', 'IRatEOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_used_in_mins, mae_ = utils_models.test_of_robustness(model=test_model,\n",
    "                                                        model_tr=test_model_tr,\n",
    "                                                        time_steps=time_step_keys,\n",
    "                                                        X_test_data=test_raw,\n",
    "                                                        y_test_data=y_test_raw,\n",
    "                                                        targets=targets,\n",
    "                                                        step_size_dict=step_size_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the errors against the times in minutes: cycle model\n",
    "list_of_markers = [\"s-\", \"o-\", \"<-\", \">-\", \"*-\"]\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "for i in range(len(targets)):\n",
    "    ax.plot(time_used_in_mins, mae[:, i], list_of_markers[i], label=targets[i])\n",
    "    ax.set_xlabel('Sub-sampling time steps (mins)', fontsize=16)\n",
    "    ax.set_ylabel('MAE (Cycles)', fontsize=16)\n",
    "\n",
    "#handles, labels = ax[0].get_legend_handles_labels()\n",
    "#ax[0].legend(handles, labels, loc='upper center', ncol=5, bbox_to_anchor=(1.0, -0.2))\n",
    "ax.legend()\n",
    "plt.savefig(fname=\"plots/sig-robust-cycles.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the errors against the times in minutes: capacity-ir model\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "for i in range(2, 5):\n",
    "    ax.plot(time_used_in_mins, mae_[:, i], list_of_markers[i], label=targets[i])\n",
    "    ax.set_xlabel('Sub-sampling time steps (mins)', fontsize=16)\n",
    "    #ax.set_ylabel('MAE (Ah)', fontsize=16)\n",
    "    ax.set_ylabel(r'MAE ($\\Omega$)', fontsize=16)\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig(fname=\"plots/sig-robust-ir.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
