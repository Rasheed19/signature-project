{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "from utils import utils_gn, utils_sig, utils_dgrd, utils_models\n",
    "import importlib\n",
    "importlib.reload(utils_gn)\n",
    "importlib.reload(utils_sig)\n",
    "importlib.reload(utils_models)\n",
    "importlib.reload(utils_dgrd)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train raw data\n",
    "train_raw = utils_gn.read_data('train_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_raw = utils_gn.read_data('test_1238.pkl')\n",
    "y_test = utils_gn.read_data('true_test_labels_1238.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target list\n",
    "target_list = ['k-o', 'k-p', 'e-o', 'e-p', 'EOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "n = 100\n",
    "sig_level = 2\n",
    "multi_cycle = False\n",
    "step_size = 1\n",
    "#step_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set to predict cycles\n",
    "tr = utils_gn.FeatureTransformation(n=n, step_size=step_size)\n",
    "X_train, y_train = tr.fit_transform(data=train_raw, targets=target_list, with_eol=True, sig_level=sig_level, multi_cycle=multi_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set\n",
    "X_test, y_test = tr.transform(test_raw, sig_level=sig_level, multi_cycle=multi_cycle), y_test[target_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model to predict knees, elbows and end-of-life      \n",
    "params = {'n_estimators': 100, 'reg_alpha': 0.001, 'max_depth': 2, 'min_samples_split': 3}\n",
    "model = utils_models.ModelPipeline(params=params, transform_target=True)\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training metrics and their confidence intervals\n",
    "train_pred = model.predict(X_train)\n",
    "train_scores = utils_models.metrics_calculator(y_train, train_pred, multi=True)\n",
    "train_scores = pd.DataFrame.from_dict(train_scores)\n",
    "train_scores['MAE CI'] = utils_models.confidence_interval_metrics(actual=y_train, predictions=train_pred, n_bootstraps=10000, target_list=target_list, metric_type='mae')\n",
    "train_scores['MAPE CI'] = utils_models.confidence_interval_metrics(actual=y_train, predictions=train_pred, n_bootstraps=10000, target_list=target_list, metric_type='mape')\n",
    "train_scores['RMSE CI'] = utils_models.confidence_interval_metrics(actual=y_train, predictions=train_pred, n_bootstraps=10000, target_list=target_list, metric_type='rmse')\n",
    "train_scores.index = target_list\n",
    "'''\n",
    "train_scores = train_scores[['MAE', 'MAE CI', 'MAPE', 'MAPE CI', 'RMSE', 'RMSE CI']] \n",
    "train_scores['MAE pm'] = abs(train_scores['MAE'] - train_scores['MAE CI'])\n",
    "train_scores['RMSE pm'] = abs(train_scores['RMSE'] - train_scores['RMSE CI'])\n",
    "train_scores['MAE mean pm'] = [np.mean(item) for item in train_scores['MAE pm'].values]\n",
    "train_scores['RMSE mean pm'] = [np.mean(item) for item in train_scores['RMSE pm'].values]\n",
    "#train_scores = train_scores[['MAE', 'MAE CI', 'MAE pm', 'MAE mean pm', 'RMSE', 'RMSE CI', 'RMSE pm', 'RMSE mean pm']]\n",
    "train_scores = train_scores[['MAE', 'MAE CI', 'RMSE', 'RMSE CI']]\n",
    "'''\n",
    "display(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test metrics and their confidence intervals\n",
    "test_pred = model.predict(X_test)\n",
    "test_scores = utils_models.metrics_calculator(y_test, test_pred, multi=True)\n",
    "test_scores = pd.DataFrame.from_dict(test_scores)\n",
    "test_scores['MAE CI'] = utils_models.confidence_interval_metrics(actual=y_test, predictions=test_pred, n_bootstraps=10000, target_list=target_list, metric_type='mae')\n",
    "test_scores['MAPE CI'] = utils_models.confidence_interval_metrics(actual=y_test, predictions=test_pred, n_bootstraps=10000, target_list=target_list, metric_type='mape')\n",
    "test_scores['RMSE CI'] = utils_models.confidence_interval_metrics(actual=y_test, predictions=test_pred, n_bootstraps=10000, target_list=target_list, metric_type='rmse')\n",
    "test_scores.index = target_list\n",
    "'''\n",
    "test_scores = test_scores[['MAE', 'MAE CI', 'MAPE', 'MAPE CI', 'RMSE', 'RMSE CI']]\n",
    "test_scores['MAE pm'] = abs(test_scores['MAE'] - test_scores['MAE CI'])\n",
    "test_scores['RMSE pm'] = abs(test_scores['RMSE'] - test_scores['RMSE CI'])\n",
    "test_scores['MAE mean pm'] = [np.mean(item) for item in test_scores['MAE pm'].values]\n",
    "test_scores['RMSE mean pm'] = [np.mean(item) for item in test_scores['RMSE pm'].values]\n",
    "#test_scores = test_scores[['MAE', 'MAE CI', 'MAE pm', 'MAE mean pm', 'RMSE', 'RMSE CI', 'RMSE pm', 'RMSE mean pm']]\n",
    "test_scores = test_scores[['MAE', 'MAE CI', 'RMSE', 'RMSE CI']]\n",
    "'''\n",
    "display(test_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train predictions and true train labels \n",
    "with open(os.path.join(\"models\", \"sig_cycles_train_labels.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(y_train, fp)\n",
    "\n",
    "with open(os.path.join(\"models\", \"sig_cycles_train_pred.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(train_pred, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open(os.path.join(\"models\", \"sig_cycles.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(model, fp)\n",
    "\n",
    "# Save transformation\n",
    "with open(os.path.join(\"models\", \"sig_cycles_trans.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(tr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction intervals and save as pickle file\n",
    "pred_interval, v_list = utils_models.prediction_interval(X=X_train, y=y_train, model=model, n_bootstraps=100,\n",
    "                                                         target_list=target_list, predictions=test_pred, confidence_level=0.90, plot_dist=True)\n",
    "                                                         \n",
    "with open(os.path.join(\"models\", \"sig_cycles_pred_interval.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(pred_interval, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
